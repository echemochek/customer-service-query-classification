{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Service Query Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libaries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Customer_Service_Questions_Multiclass.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "# missingno.matrix(df) # there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# distribution of the topics column\\nsns.countplot(x=df[\"topic\"])\\nplt.xlabel(\"Topic\")\\nplt.ylabel(\"Frequency\")\\nplt.xticks(rotation=65)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# distribution of the topics column\n",
    "sns.countplot(x=df[\"topic\"])\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=65)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "# encoding the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(df['topic'])\n",
    "df['category'] = encoder.transform(df['topic'])\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.question, df.category, stratify=df.category, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data in different formats\n",
    "\n",
    "1. TF-IDF vector\n",
    "2. TF-IDF vector of n-grams\n",
    "3. Word vectors (GloVe)\n",
    "4. Document vectors (Doc2Vec)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', \n",
    "                            stop_words='english', max_df=0.95, min_df=0.05, max_features=500\n",
    "                            )\n",
    "vectorizer.fit(df.question)\n",
    "\n",
    "dfTfidf_train = vectorizer.transform(xtrain)\n",
    "dfTfidf_test = vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF n-grams vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector of n-grams\n",
    "ngrams_vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', ngram_range=(2,3), \n",
    "                            max_df=0.95, min_df=0.05, max_features=500\n",
    "                            )\n",
    "ngrams_vectorizer.fit(df.question)\n",
    "\n",
    "dfTfidf_ngrams_train = ngrams_vectorizer.transform(xtrain)\n",
    "dfTfidf_ngrams_test = ngrams_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (4000, 100) \n",
      "Test features shape: (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Word vectors \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wordvec = Word2Vec(xtrain, window=8, min_count=2, sample=1e-3, sg=1, workers=8)\n",
    "vocab = set(wordvec.wv.index_to_key)\n",
    "\n",
    "num_features = 100\n",
    "\n",
    "def average_word_vectors(tokens, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    ntokens = 0.\n",
    "    for t in tokens:\n",
    "        if t in vocabulary: \n",
    "            ntokens = ntokens + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[t])\n",
    "    if ntokens:\n",
    "        feature_vector = np.divide(feature_vector, ntokens)\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "word2vec_train = [average_word_vectors(sent_tokens, wordvec, vocab, num_features) \n",
    "               for sent_tokens in xtrain]\n",
    "avg_word2vec_train = np.array(word2vec_train)\n",
    "\n",
    "word2vec_test = [average_word_vectors(sent_tokens, wordvec, vocab, num_features) \n",
    "              for sent_tokens in xtest]\n",
    "avg_word2vec_test = np.array(word2vec_test)\n",
    "\n",
    "print('Train features shape:', avg_word2vec_train.shape, \n",
    "      '\\nTest features shape:', avg_word2vec_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(xtrain)]\n",
    "docvec = Doc2Vec(vector_size=100, window=3, min_count=4, workers=4, epochs=40)\n",
    "docvec.build_vocab(docs)\n",
    "docvec.train(docs, total_examples=docvec.corpus_count, epochs=docvec.epochs)\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "xtrainTokenized = [simple_preprocess(h) for h in xtrain]\n",
    "xtestTokenized = [simple_preprocess(h) for h in xtest]\n",
    "\n",
    "docvec_train = [docvec.infer_vector(i) for i in xtrainTokenized]\n",
    "docvec_test =  [docvec.infer_vector(i) for i in xtestTokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to consider:\n",
    "-\n",
    "1. One multi-class classifier (e.g., Naive Bayes, Logistic, Decision Tree, SVM)\n",
    "2. One ensemble classifier whose code is also provided (e.g., Random Forest, XGBoost)\n",
    "3. One other model of your choice whose code is NOT provided in class handouts\n",
    "\n",
    "Input features to consider for each model:\n",
    "-\n",
    "1. TF-IDF vector of tokenized words\n",
    "2. TF-IDF vector of n-grams (of range 4-5)\n",
    "3. Word vectors (Glove, Word2Vec, or FastText)\n",
    "4. Document vectors (Doc2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "model_SVC_tfidf = svc.fit(dfTfidf_train, ytrain)\n",
    "svc_tfidf_pred = model_SVC_tfidf.predict(dfTfidf_test)\n",
    "\n",
    "# n-grams tf-idf\n",
    "model_SVC_ngramTfidf = svc.fit(dfTfidf_ngrams_train, ytrain)\n",
    "svc_ngram_tfidf_pred = model_SVC_ngramTfidf.predict(dfTfidf_ngrams_test)\n",
    "\n",
    "# word vectors\n",
    "model_SVC_word2vec = svc.fit(avg_word2vec_train, ytrain)\n",
    "svc_word2vec_pred = model_SVC_word2vec.predict(avg_word2vec_test)\n",
    "\n",
    "# document vectors\n",
    "model_SVC_doc2vec = svc.fit(docvec_train, ytrain)\n",
    "svc_doc2vec_pred = model_SVC_doc2vec.predict(docvec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.90      0.83      0.87        90\n",
      "  Product Availability       0.53      0.83      0.65       167\n",
      "    Product Comparison       0.69      0.49      0.57       161\n",
      "Product Specifications       0.67      0.65      0.66       168\n",
      "     Returns & Refunds       0.98      0.97      0.98       153\n",
      "      Sales/Promotions       0.70      0.49      0.57       101\n",
      "              Shipping       0.93      0.92      0.92       160\n",
      "\n",
      "              accuracy                           0.75      1000\n",
      "             macro avg       0.77      0.74      0.75      1000\n",
      "          weighted avg       0.76      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc tf-idf\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nTF-IDF\\n\", classification_report(ytest, svc_tfidf_pred)) # not removing stopwords improves the model significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF n-grams\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.85      0.74      0.79        90\n",
      "  Product Availability       0.81      0.89      0.85       167\n",
      "    Product Comparison       0.88      0.66      0.76       161\n",
      "Product Specifications       0.60      0.83      0.69       168\n",
      "     Returns & Refunds       0.78      0.82      0.80       153\n",
      "      Sales/Promotions       0.77      0.48      0.59       101\n",
      "              Shipping       0.85      0.84      0.85       160\n",
      "\n",
      "              accuracy                           0.77      1000\n",
      "             macro avg       0.79      0.75      0.76      1000\n",
      "          weighted avg       0.79      0.77      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc n-grams tf-idf\n",
    "print(\"\\nTF-IDF n-grams\\n\", classification_report(ytest, svc_ngram_tfidf_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vectors\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.86      0.07      0.12        90\n",
      "  Product Availability       0.48      0.86      0.62       167\n",
      "    Product Comparison       0.72      0.48      0.57       161\n",
      "Product Specifications       0.45      0.40      0.43       168\n",
      "     Returns & Refunds       0.55      0.59      0.57       153\n",
      "      Sales/Promotions       0.87      0.13      0.22       101\n",
      "              Shipping       0.46      0.73      0.56       160\n",
      "\n",
      "              accuracy                           0.52      1000\n",
      "             macro avg       0.63      0.47      0.44      1000\n",
      "          weighted avg       0.59      0.52      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word vectors\n",
    "print(\"\\nWord vectors\\n\", classification_report(ytest, svc_word2vec_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       1.00      0.16      0.27        90\n",
      "  Product Availability       0.82      0.60      0.69       167\n",
      "    Product Comparison       0.21      0.30      0.25       161\n",
      "Product Specifications       0.22      0.36      0.27       168\n",
      "     Returns & Refunds       0.44      0.32      0.37       153\n",
      "      Sales/Promotions       1.00      0.46      0.63       101\n",
      "              Shipping       0.24      0.28      0.26       160\n",
      "\n",
      "              accuracy                           0.36      1000\n",
      "             macro avg       0.56      0.35      0.39      1000\n",
      "          weighted avg       0.50      0.36      0.39      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document vectors\n",
    "print(\"\\nDocument Vectors\\n\", classification_report(ytest, svc_doc2vec_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works well with scaled/normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfTfidf_train\n",
    "#dfTfidf_ngrams_train\n",
    "#avg_word2vec_train\n",
    "#docvec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "model_xgb_tfidf = xgb_cl.fit(dfTfidf_train, ytrain)\n",
    "xgb_tfidf_pred = model_xgb_tfidf.predict(dfTfidf_test)\n",
    "\n",
    "# n-grams tf-idf\n",
    "model_xgb_ngramTfidf = xgb_cl.fit(dfTfidf_ngrams_train, ytrain)\n",
    "xgb_ngram_tfidf_pred = model_xgb_ngramTfidf.predict(dfTfidf_ngrams_test)\n",
    "\n",
    "# word vectors\n",
    "model_xgb_word2vec = xgb_cl.fit(avg_word2vec_train, ytrain)\n",
    "xgb_word2vec_pred = model_xgb_word2vec.predict(avg_word2vec_test)\n",
    "\n",
    "# document vectors\n",
    "model_xgb_doc2vec = xgb_cl.fit(docvec_train, ytrain)\n",
    "xgb_doc2vec_pred = model_xgb_doc2vec.predict(docvec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88        90\n",
      "           1       0.54      0.84      0.66       167\n",
      "           2       0.75      0.50      0.60       161\n",
      "           3       0.68      0.68      0.68       168\n",
      "           4       0.93      0.98      0.95       153\n",
      "           5       0.81      0.53      0.64       101\n",
      "           6       0.96      0.94      0.95       160\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.80      0.76      0.77      1000\n",
      "weighted avg       0.79      0.76      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc tf-idf\n",
    "print(\"\\nTF-IDF\\n\", classification_report(ytest, xgb_tfidf_pred)) # not removing stopwords improves the model significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF n-grams\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85        90\n",
      "           1       0.81      0.90      0.86       167\n",
      "           2       0.87      0.70      0.77       161\n",
      "           3       0.60      0.82      0.69       168\n",
      "           4       0.78      0.82      0.80       153\n",
      "           5       0.86      0.50      0.64       101\n",
      "           6       0.87      0.87      0.87       160\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.82      0.77      0.78      1000\n",
      "weighted avg       0.81      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc n-grams tf-idf\n",
    "print(\"\\nTF-IDF n-grams\\n\", classification_report(ytest, xgb_ngram_tfidf_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88        90\n",
      "           1       0.89      0.89      0.89       167\n",
      "           2       0.74      0.81      0.77       161\n",
      "           3       0.72      0.69      0.71       168\n",
      "           4       0.90      0.90      0.90       153\n",
      "           5       0.87      0.80      0.84       101\n",
      "           6       0.88      0.91      0.89       160\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.84      0.83      0.84      1000\n",
      "weighted avg       0.84      0.83      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word vectors\n",
    "print(\"\\nWord vectors\\n\", classification_report(ytest, xgb_word2vec_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.26      0.35        90\n",
      "           1       0.82      0.65      0.72       167\n",
      "           2       0.22      0.28      0.24       161\n",
      "           3       0.25      0.33      0.28       168\n",
      "           4       0.48      0.37      0.42       153\n",
      "           5       0.84      0.61      0.71       101\n",
      "           6       0.21      0.28      0.24       160\n",
      "\n",
      "    accuracy                           0.39      1000\n",
      "   macro avg       0.48      0.40      0.42      1000\n",
      "weighted avg       0.46      0.39      0.41      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document vectors\n",
    "print(\"\\nDocument Vectors\\n\", classification_report(ytest, xgb_doc2vec_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use PyTorch in this case. Refere here: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfe9ce709e982859ebd8c1b094ee35d9f73a27801040ad55cc46450c9d5cadda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
