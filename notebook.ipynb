{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Service Query Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libaries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import get_scorer \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store metrics of different models\n",
    "\n",
    "modelMetrics = {\n",
    "                'svc': {'tfidf': [], 'tfidf_ngrams': [], 'word2vec': [], 'doc2vec': []},\n",
    "                'xgboost': {'tfidf': [], 'tfidf_ngrams': [], 'word2vec': [], 'doc2vec': []},\n",
    "                'knn': {'tfidf': [], 'tfidf_ngrams': [], 'word2vec': [], 'doc2vec': []}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Customer_Service_Questions_Multiclass.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "# missingno.matrix(df) # there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "# distribution of the topics column\n",
    "sns.countplot(x=df[\"topic\"], color = \"grey\")\n",
    "plt.title(\"Distribution by Department\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=65)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "# encoding the labels\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(df['topic'])\n",
    "df['category'] = encoder.transform(df['topic'])\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.question, df.category, stratify=df.category, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data in different formats\n",
    "\n",
    "1. TF-IDF vector\n",
    "2. TF-IDF vector of n-grams\n",
    "3. Word vectors (GloVe)\n",
    "4. Document vectors (Doc2Vec)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector\n",
    "vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', \n",
    "                            stop_words='english', max_df=0.95, min_df=0.05, max_features=500\n",
    "                            )\n",
    "vectorizer.fit(df.question)\n",
    "\n",
    "dfTfidf_train = vectorizer.transform(xtrain)\n",
    "dfTfidf_test = vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF n-grams vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector of n-grams\n",
    "ngrams_vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', ngram_range=(2,3), \n",
    "                            max_df=0.95, min_df=0.05, max_features=500\n",
    "                            )\n",
    "ngrams_vectorizer.fit(df.question)\n",
    "\n",
    "dfTfidf_ngrams_train = ngrams_vectorizer.transform(xtrain)\n",
    "dfTfidf_ngrams_test = ngrams_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (4000, 100) \n",
      "Test features shape: (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Word vectors \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wordvec = Word2Vec(xtrain, window=8, min_count=2, sample=1e-3, sg=1, workers=8)\n",
    "vocab = set(wordvec.wv.index_to_key)\n",
    "\n",
    "num_features = 100\n",
    "\n",
    "def average_word_vectors(tokens, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    ntokens = 0.\n",
    "    for t in tokens:\n",
    "        if t in vocabulary: \n",
    "            ntokens = ntokens + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[t])\n",
    "    if ntokens:\n",
    "        feature_vector = np.divide(feature_vector, ntokens)\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "word2vec_train = [average_word_vectors(sent_tokens, wordvec, vocab, num_features) \n",
    "               for sent_tokens in xtrain]\n",
    "avg_word2vec_train = np.array(word2vec_train)\n",
    "\n",
    "word2vec_test = [average_word_vectors(sent_tokens, wordvec, vocab, num_features) \n",
    "              for sent_tokens in xtest]\n",
    "avg_word2vec_test = np.array(word2vec_test)\n",
    "\n",
    "print('Train features shape:', avg_word2vec_train.shape, \n",
    "      '\\nTest features shape:', avg_word2vec_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vector\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(xtrain)]\n",
    "docvec = Doc2Vec(vector_size=100, window=3, min_count=4, workers=4, epochs=40)\n",
    "docvec.build_vocab(docs)\n",
    "docvec.train(docs, total_examples=docvec.corpus_count, epochs=docvec.epochs)\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "xtrainTokenized = [simple_preprocess(h) for h in xtrain]\n",
    "xtestTokenized = [simple_preprocess(h) for h in xtest]\n",
    "\n",
    "docvec_train = [docvec.infer_vector(i) for i in xtrainTokenized]\n",
    "docvec_test =  [docvec.infer_vector(i) for i in xtestTokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to consider:\n",
    "-\n",
    "1. One multi-class classifier (e.g., Naive Bayes, Logistic, Decision Tree, SVM)\n",
    "2. One ensemble classifier whose code is also provided (e.g., Random Forest, XGBoost)\n",
    "3. One other model of your choice whose code is NOT provided in class handouts\n",
    "\n",
    "Input features to consider for each model:\n",
    "-\n",
    "1. TF-IDF vector of tokenized words\n",
    "2. TF-IDF vector of n-grams (of range 4-5)\n",
    "3. Word vectors (Glove, Word2Vec, or FastText)\n",
    "4. Document vectors (Doc2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "model_SVC_tfidf = svc.fit(dfTfidf_train, ytrain)\n",
    "svc_tfidf_pred = model_SVC_tfidf.predict(dfTfidf_test)\n",
    "\n",
    "# n-grams tf-idf\n",
    "model_SVC_ngramTfidf = svc.fit(dfTfidf_ngrams_train, ytrain)\n",
    "svc_ngram_tfidf_pred = model_SVC_ngramTfidf.predict(dfTfidf_ngrams_test)\n",
    "\n",
    "# word vectors\n",
    "model_SVC_word2vec = svc.fit(avg_word2vec_train, ytrain)\n",
    "svc_word2vec_pred = model_SVC_word2vec.predict(avg_word2vec_test)\n",
    "\n",
    "# document vectors\n",
    "model_SVC_doc2vec = svc.fit(docvec_train, ytrain)\n",
    "svc_doc2vec_pred = model_SVC_doc2vec.predict(docvec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = get_scorer(\"accuracy\")\n",
    "\n",
    "acc._score_func(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87        90\n",
      "           1       0.53      0.83      0.65       167\n",
      "           2       0.69      0.49      0.57       161\n",
      "           3       0.67      0.65      0.66       168\n",
      "           4       0.98      0.97      0.98       153\n",
      "           5       0.70      0.49      0.57       101\n",
      "           6       0.93      0.92      0.92       160\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.77      0.74      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc tf-idf\n",
    "print(\"\\nTF-IDF\\n\", classification_report(ytest, svc_tfidf_pred)) # not removing stopwords improves the model significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF n-grams\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        90\n",
      "           1       0.81      0.89      0.85       167\n",
      "           2       0.88      0.66      0.76       161\n",
      "           3       0.60      0.83      0.69       168\n",
      "           4       0.78      0.82      0.80       153\n",
      "           5       0.77      0.48      0.59       101\n",
      "           6       0.85      0.84      0.85       160\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.79      0.75      0.76      1000\n",
      "weighted avg       0.79      0.77      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc n-grams tf-idf\n",
    "print(\"\\nTF-IDF n-grams\\n\", classification_report(ytest, svc_ngram_tfidf_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.10      0.18        90\n",
      "           1       0.47      0.87      0.61       167\n",
      "           2       0.74      0.52      0.61       161\n",
      "           3       0.45      0.39      0.41       168\n",
      "           4       0.54      0.56      0.55       153\n",
      "           5       0.78      0.07      0.13       101\n",
      "           6       0.47      0.74      0.58       160\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.62      0.47      0.44      1000\n",
      "weighted avg       0.59      0.52      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word vectors\n",
    "print(\"\\nWord vectors\\n\", classification_report(ytest, svc_word2vec_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        90\n",
      "           1       0.80      0.60      0.68       167\n",
      "           2       0.23      0.35      0.28       161\n",
      "           3       0.19      0.34      0.25       168\n",
      "           4       0.44      0.31      0.37       153\n",
      "           5       0.98      0.41      0.57       101\n",
      "           6       0.23      0.25      0.24       160\n",
      "\n",
      "    accuracy                           0.36      1000\n",
      "   macro avg       0.55      0.34      0.38      1000\n",
      "weighted avg       0.50      0.36      0.38      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document vectors\n",
    "print(\"\\nDocument Vectors\\n\", classification_report(ytest, svc_doc2vec_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.677 total time=   0.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.639 total time=   0.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.705 total time=   0.7s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.693 total time=   0.4s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.681 total time=   0.4s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.682 total time=   0.5s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.705 total time=   0.5s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.651 total time=   0.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.652 total time=   0.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.616 total time=   0.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.641 total time=   0.5s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.615 total time=   0.4s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.677 total time=   0.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.639 total time=   0.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.637 total time=   0.7s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.6s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.611 total time=   0.6s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.586 total time=   0.6s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.584 total time=   0.7s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.545 total time=   0.7s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.509 total time=   0.6s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.517 total time=   0.6s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.499 total time=   0.6s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.496 total time=   0.6s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.677 total time=   0.3s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.639 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.657 total time=   0.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.677 total time=   0.4s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.639 total time=   0.2s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.657 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.169 total time=   0.6s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.9s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.8s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.677 total time=   0.4s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.639 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.657 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.657 total time=   0.4s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.169 total time=   0.8s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.6s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.666 total time=   0.1s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.735 total time=   0.2s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.715 total time=   0.2s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.715 total time=   0.3s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.724 total time=   0.2s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.739 total time=   0.2s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.601 total time=   0.3s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.596 total time=   0.3s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.562 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.564 total time=   0.3s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.569 total time=   0.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.685 total time=   0.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.666 total time=   0.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.694 total time=   0.3s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.689 total time=   0.3s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.672 total time=   0.3s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.675 total time=   0.3s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.686 total time=   0.3s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.672 total time=   0.4s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.677 total time=   0.4s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.639 total time=   0.3s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.659 total time=   0.3s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.657 total time=   0.3s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.685 total time=   0.1s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.6s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.593 total time=   0.6s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.583 total time=   0.7s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.573 total time=   0.7s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.573 total time=   0.7s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.545 total time=   0.7s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.509 total time=   0.6s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.517 total time=   0.7s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.500 total time=   0.7s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.496 total time=   0.7s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.685 total time=   0.3s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.168 total time=   1.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.169 total time=   0.6s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.169 total time=   0.8s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.6s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.169 total time=   0.6s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.6s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.686 total time=   0.3s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.695 total time=   0.2s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.690 total time=   0.2s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.694 total time=   0.3s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.736 total time=   0.2s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.731 total time=   0.2s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.724 total time=   0.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.729 total time=   0.3s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.751 total time=   0.3s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.579 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.573 total time=   0.3s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.556 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.570 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.578 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.686 total time=   0.4s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.695 total time=   0.3s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.690 total time=   0.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.694 total time=   0.4s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.674 total time=   0.4s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.704 total time=   0.2s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.706 total time=   0.2s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.694 total time=   0.2s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.3s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.684 total time=   0.2s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.682 total time=   0.3s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.676 total time=   0.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.680 total time=   0.2s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.666 total time=   0.3s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.686 total time=   0.4s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.695 total time=   0.3s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.690 total time=   0.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.694 total time=   0.3s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.682 total time=   0.3s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.681 total time=   0.4s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.664 total time=   0.3s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.651 total time=   0.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.670 total time=   0.3s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.672 total time=   0.4s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.677 total time=   0.3s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.639 total time=   0.4s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.657 total time=   0.4s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.657 total time=   0.5s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.686 total time=   0.3s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.695 total time=   0.4s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.690 total time=   0.3s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.694 total time=   0.3s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.674 total time=   0.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.611 total time=   0.6s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.595 total time=   0.7s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.583 total time=   0.6s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.573 total time=   0.8s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.571 total time=   0.7s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.545 total time=   0.7s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.509 total time=   0.6s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.517 total time=   0.7s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.500 total time=   0.6s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.496 total time=   0.7s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.686 total time=   0.3s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.695 total time=   0.2s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.690 total time=   0.3s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.694 total time=   0.3s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.674 total time=   0.5s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.169 total time=   0.7s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.6s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.6s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.7s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.168 total time=   0.8s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.169 total time=   0.6s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.8s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.168 total time=   0.7s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.690 total time=   1.7s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.696 total time=   1.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.693 total time=   1.1s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.700 total time=   1.1s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.671 total time=   1.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.739 total time=   0.2s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.734 total time=   0.2s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.724 total time=   0.2s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.729 total time=   0.2s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.750 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.573 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.581 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.568 total time=   0.3s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.541 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.590 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.690 total time=   1.8s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.696 total time=   1.1s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.693 total time=   1.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.700 total time=   1.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.671 total time=   1.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.731 total time=   0.3s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.723 total time=   0.3s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.724 total time=   0.3s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.724 total time=   0.4s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.688 total time=   0.3s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.681 total time=   0.3s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.684 total time=   0.3s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.694 total time=   0.4s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.669 total time=   0.4s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.690 total time=   1.5s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.696 total time=   0.9s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.693 total time=   1.1s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.700 total time=   1.2s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.671 total time=   1.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.689 total time=   0.3s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.690 total time=   0.2s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.676 total time=   0.3s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.695 total time=   0.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.680 total time=   0.3s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.690 total time=   1.7s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.696 total time=   1.0s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.693 total time=   1.5s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.700 total time=   1.1s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.671 total time=   1.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.682 total time=   0.4s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.684 total time=   0.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.665 total time=   0.3s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.651 total time=   0.3s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.670 total time=   0.3s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.672 total time=   0.3s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.677 total time=   0.4s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.639 total time=   0.5s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.657 total time=   0.4s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.657 total time=   0.3s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.690 total time=   1.7s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.696 total time=   1.2s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.693 total time=   1.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.700 total time=   1.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.671 total time=   0.9s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.611 total time=   0.5s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.595 total time=   0.6s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.585 total time=   0.6s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.573 total time=   0.6s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.573 total time=   0.7s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.545 total time=   0.6s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.509 total time=   0.7s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.517 total time=   0.7s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.500 total time=   0.6s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.496 total time=   0.7s\n",
      "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.691 total time=  14.3s\n",
      "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.698 total time=   8.7s\n",
      "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.689 total time=  10.2s\n",
      "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.698 total time=   9.0s\n",
      "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.674 total time=   8.9s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.739 total time=   0.3s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.734 total time=   0.2s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.721 total time=   0.2s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.730 total time=   0.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.749 total time=   0.3s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.569 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.593 total time=   0.3s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.547 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.559 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.580 total time=   0.2s\n",
      "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.691 total time=  13.2s\n",
      "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.698 total time=   8.2s\n",
      "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.689 total time=  10.4s\n",
      "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.698 total time=   9.2s\n",
      "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.674 total time=   8.6s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.6s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.8s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.724 total time=   0.5s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.6s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.743 total time=   0.4s\n",
      "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.637 total time=   0.6s\n",
      "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.644 total time=   0.6s\n",
      "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.636 total time=   0.6s\n",
      "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.637 total time=   0.8s\n",
      "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.645 total time=   0.7s\n",
      "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.691 total time=  12.8s\n",
      "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.698 total time=   8.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.689 total time=  12.4s\n",
      "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.698 total time=  12.2s\n",
      "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.674 total time=  10.3s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.705 total time=   0.5s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.689 total time=   0.5s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.715 total time=   0.5s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.701 total time=   0.6s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.708 total time=   0.5s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.686 total time=   0.6s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.695 total time=   0.6s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.690 total time=   0.5s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.694 total time=   0.7s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.674 total time=   0.7s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.691 total time=  14.2s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.698 total time=   8.3s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.689 total time=  10.9s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.698 total time=  12.1s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.674 total time=   8.4s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.686 total time=   0.3s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.689 total time=   0.3s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.677 total time=   0.3s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.694 total time=   0.4s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.685 total time=   0.3s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.682 total time=   0.2s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.666 total time=   0.3s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.691 total time=  11.6s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.698 total time=   7.5s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.689 total time=   9.4s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.698 total time=   9.5s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.674 total time=   8.5s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.682 total time=   0.3s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.684 total time=   0.3s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.666 total time=   0.4s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.651 total time=   0.3s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.670 total time=   0.4s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.672 total time=   0.5s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.639 total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.657 total time=   0.4s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.657 total time=   0.4s\n",
      "SVC(C=100, gamma=1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87        90\n",
      "           1       0.54      0.84      0.66       167\n",
      "           2       0.74      0.47      0.58       161\n",
      "           3       0.66      0.65      0.65       168\n",
      "           4       0.94      0.97      0.96       153\n",
      "           5       0.78      0.51      0.62       101\n",
      "           6       0.94      0.94      0.94       160\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.78      0.75      0.75      1000\n",
      "weighted avg       0.77      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(svc, param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(dfTfidf_train, ytrain)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "grid_predictions = grid.predict(dfTfidf_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(ytest, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works well with scaled/normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "model_xgb_tfidf = xgb_cl.fit(dfTfidf_train, ytrain)\n",
    "xgb_tfidf_pred = model_xgb_tfidf.predict(dfTfidf_test)\n",
    "\n",
    "# n-grams tf-idf\n",
    "model_xgb_ngramTfidf = xgb_cl.fit(dfTfidf_ngrams_train, ytrain)\n",
    "xgb_ngram_tfidf_pred = model_xgb_ngramTfidf.predict(dfTfidf_ngrams_test)\n",
    "\n",
    "# word vectors\n",
    "model_xgb_word2vec = xgb_cl.fit(avg_word2vec_train, ytrain)\n",
    "xgb_word2vec_pred = model_xgb_word2vec.predict(avg_word2vec_test)\n",
    "\n",
    "# document vectors\n",
    "model_xgb_doc2vec = xgb_cl.fit(docvec_train, ytrain)\n",
    "xgb_doc2vec_pred = model_xgb_doc2vec.predict(docvec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88        90\n",
      "           1       0.54      0.84      0.66       167\n",
      "           2       0.75      0.50      0.60       161\n",
      "           3       0.68      0.68      0.68       168\n",
      "           4       0.93      0.98      0.95       153\n",
      "           5       0.81      0.53      0.64       101\n",
      "           6       0.96      0.94      0.95       160\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.80      0.76      0.77      1000\n",
      "weighted avg       0.79      0.76      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost tf-idf\n",
    "print(\"\\nTF-IDF\\n\", classification_report(ytest, xgb_tfidf_pred)) # not removing stopwords improves the model significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF n-grams\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85        90\n",
      "           1       0.81      0.90      0.86       167\n",
      "           2       0.87      0.70      0.77       161\n",
      "           3       0.60      0.82      0.69       168\n",
      "           4       0.78      0.82      0.80       153\n",
      "           5       0.86      0.50      0.64       101\n",
      "           6       0.87      0.87      0.87       160\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.82      0.77      0.78      1000\n",
      "weighted avg       0.81      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost n-grams tf-idf\n",
    "print(\"\\nTF-IDF n-grams\\n\", classification_report(ytest, xgb_ngram_tfidf_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        90\n",
      "           1       0.94      0.90      0.92       167\n",
      "           2       0.76      0.81      0.78       161\n",
      "           3       0.73      0.68      0.70       168\n",
      "           4       0.89      0.93      0.91       153\n",
      "           5       0.89      0.81      0.85       101\n",
      "           6       0.88      0.94      0.91       160\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost word vectors\n",
    "print(\"\\nWord vectors\\n\", classification_report(ytest, xgb_word2vec_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        90\n",
      "           1       0.81      0.66      0.73       167\n",
      "           2       0.22      0.30      0.26       161\n",
      "           3       0.21      0.27      0.24       168\n",
      "           4       0.36      0.37      0.36       153\n",
      "           5       0.94      0.59      0.73       101\n",
      "           6       0.27      0.29      0.28       160\n",
      "\n",
      "    accuracy                           0.39      1000\n",
      "   macro avg       0.48      0.39      0.42      1000\n",
      "weighted avg       0.45      0.39      0.41      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost document vectors\n",
    "print(\"\\nDocument Vectors\\n\", classification_report(ytest, xgb_doc2vec_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "model_knn_tfidf = knn_clf.fit(dfTfidf_train, ytrain)\n",
    "knn_tfidf_pred = model_knn_tfidf.predict(dfTfidf_test)\n",
    "\n",
    "# n-grams tf-idf\n",
    "model_knn_ngramTfidf = knn_clf.fit(dfTfidf_ngrams_train, ytrain)\n",
    "knn_ngram_tfidf_pred = model_knn_ngramTfidf.predict(dfTfidf_ngrams_test)\n",
    "\n",
    "# word vectors\n",
    "model_knn_word2vec = knn_clf.fit(avg_word2vec_train, ytrain)\n",
    "knn_word2vec_pred = model_knn_word2vec.predict(avg_word2vec_test)\n",
    "\n",
    "# document vectors\n",
    "model_knn_doc2vec = knn_clf.fit(docvec_train, ytrain)\n",
    "knn_doc2vec_pred = model_knn_doc2vec.predict(docvec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.93      0.54        90\n",
      "           1       0.75      0.54      0.63       167\n",
      "           2       0.63      0.42      0.50       161\n",
      "           3       0.63      0.56      0.59       168\n",
      "           4       0.92      0.95      0.94       153\n",
      "           5       0.70      0.58      0.64       101\n",
      "           6       0.93      0.94      0.93       160\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.71      0.70      0.68      1000\n",
      "weighted avg       0.73      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn n-grams tf-idf\n",
    "print(\"\\nTF-IDF\\n\", classification_report(ytest, knn_tfidf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF n-grams\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75        90\n",
      "           1       0.56      0.87      0.68       167\n",
      "           2       0.83      0.68      0.75       161\n",
      "           3       0.66      0.63      0.64       168\n",
      "           4       0.72      0.79      0.76       153\n",
      "           5       0.78      0.43      0.55       101\n",
      "           6       0.87      0.76      0.81       160\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.74      0.70      0.71      1000\n",
      "weighted avg       0.74      0.71      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn n-grams tf-idf\n",
    "print(\"\\nTF-IDF n-grams\\n\", classification_report(ytest, knn_ngram_tfidf_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76        90\n",
      "           1       0.89      0.84      0.87       167\n",
      "           2       0.76      0.83      0.79       161\n",
      "           3       0.79      0.48      0.59       168\n",
      "           4       0.80      0.86      0.83       153\n",
      "           5       0.86      0.75      0.80       101\n",
      "           6       0.74      0.91      0.81       160\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.79      0.79      0.78      1000\n",
      "weighted avg       0.79      0.79      0.78      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn word vectors\n",
    "print(\"\\nWord vectors\\n\", classification_report(ytest, knn_word2vec_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.20      0.17        90\n",
      "           1       0.49      0.61      0.54       167\n",
      "           2       0.18      0.20      0.19       161\n",
      "           3       0.22      0.23      0.22       168\n",
      "           4       0.36      0.31      0.33       153\n",
      "           5       0.35      0.38      0.36       101\n",
      "           6       0.29      0.16      0.21       160\n",
      "\n",
      "    accuracy                           0.30      1000\n",
      "   macro avg       0.29      0.30      0.29      1000\n",
      "weighted avg       0.30      0.30      0.30      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn document vectors\n",
    "print(\"\\nDocument Vectors\\n\", classification_report(ytest, knn_doc2vec_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use PyTorch in this case. Refere here: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f and here: https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "\n",
    "#from transformers import BertTokenizer\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI: LIME/SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME requires a model pipeline as input; so we have to convert the TDIDF vectorizer into a pipeline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "pipeline = make_pipeline(tfidf, model)\n",
    "list_X_test = list(X_test)                         # Save X_test as a list of strings\n",
    "class_names = {0: 'non-disaster', 1:'disaster'}  # Save class names in a dictionary for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LIME explainer, with class names for interpretability\n",
    "exp = LimeTextExplainer(class_names=[\"Non-disaster\", \"Disaster\"])\n",
    "\n",
    "# Choose a random single prediction and explain the chosen prediction using the probability results \n",
    "# of the logistic regression predict_proba\n",
    "idx = 18\n",
    "idx_exp = exp.explain_instance(list_X_test[idx], pipeline.predict_proba)\n",
    "\n",
    "# Print results\n",
    "print('Document ID: %d' % idx)\n",
    "print('Tweet: ', list_X_test[idx])\n",
    "print('Probability disaster =', pipeline.predict_proba([list_X_test[idx]]).round(3)[0,1])\n",
    "print('True class: %s' % class_names.get(list(y_test)[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display LIME results graphically, showing contribution of each word\n",
    "\n",
    "idx_exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import shap\n",
    "\n",
    "# SHAP is quite computation intensive; we sample data from train and test set to reduce time taken\n",
    "X_train_sample = shap.sample(X_train_tfidf, 200)\n",
    "X_test_sample = shap.sample(X_test_tfidf, 10)\n",
    "\n",
    "# Using SHAP's KernelExplainer (very slow)\n",
    "exp = shap.KernelExplainer(model.predict, X_train_sample)\n",
    "\n",
    "# Calculate shap values of test sample using the explainer \n",
    "shap_values = exp.shap_values(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary plot of shap values\n",
    "# To do this, we must first convert test samples to a dataframe in order to add feature values \n",
    "# to non-tabular data for the visualisation \n",
    "\n",
    "color_test = pd.DataFrame(X_test_sample.todense())\n",
    "shap.summary_plot(shap_values, color_test, feature_names=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot to better display the distribution of shapley values \n",
    "shap.summary_plot(shap_values, color_test, feature_names=tfidf.get_feature_names(), plot_type=\"violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(exp.expected_value, shap_values[1,:], \n",
    "                color_test.iloc[1,:], feature_names=tfidf.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfe9ce709e982859ebd8c1b094ee35d9f73a27801040ad55cc46450c9d5cadda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
